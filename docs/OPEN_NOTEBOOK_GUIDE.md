# Open Notebook - Umfassende Anleitung & Use Cases

> **ğŸ“ Hinweis zur SERVER_IP:** 
> `${SERVER_IP}` ist Ihre Server-IP-Adresse, die wÃ¤hrend der Installation konfiguriert wurde.
> Finden Sie den Wert in Ihrer `.env` Datei.
> 
> **Beispiel:** Bei Server-IP `192.168.178.151` ist der Zugriff: `http://192.168.178.151:8100`

## ğŸ¯ Inhaltsverzeichnis

- [Schnellstart](#schnellstart)
- [Konfiguration](#konfiguration)
  - [CPU vs GPU fÃ¼r Speech Services](#cpu-vs-gpu-fÃ¼r-speech-services)
  - [Models in der UI konfigurieren](#models-in-der-ui-konfigurieren)
- [Use Cases](#use-cases)
  - [ğŸ™ï¸ Deutsche Podcasts erstellen](#-deutsche-podcasts-erstellen)
  - [ğŸ“º YouTube Videos transkribieren](#-youtube-videos-transkribieren)
  - [ğŸ“„ PDF Research & Analyse](#-pdf-research--analyse)
  - [ğŸ”„ Advanced Workflows](#-advanced-workflows)
- [Best Practices](#best-practices)
- [Troubleshooting](#troubleshooting)

---

## ğŸš€ Schnellstart

### Installation

Open Notebook ist bereits in AI LaunchKit integriert:

```bash
# Wizard ausfÃ¼hren
sudo bash scripts/04_wizard_local.sh

# "Open Notebook" auswÃ¤hlen
# Bei "Speech Stack" â†’ GPU wÃ¤hlen fÃ¼r 4-5x schnellere Performance
```

### Zugriff

- **UI:** `http://${SERVER_IP}:8100`
- **API:** `http://${SERVER_IP}:8101`
- **API Docs:** `http://${SERVER_IP}:8101/docs`

---

## âš™ï¸ Konfiguration

### CPU vs GPU fÃ¼r Speech Services

**Performance-Vergleich:**

| Hardware | Podcast (27 Segmente) | YouTube (10 Min) | Empfehlung |
|----------|----------------------|------------------|------------|
| **CPU** | ~90 Sekunden | ~3 Minuten | Standard-Server |
| **GPU** | ~20 Sekunden | ~45 Sekunden | NVIDIA GPU vorhanden |

**GPU aktivieren (wenn NVIDIA GPU vorhanden):**

```bash
cd ~/ai-launchkit-local

# In .env Ã¤ndern:
# Von: COMPOSE_PROFILES="...,speech,..."
# Zu:  COMPOSE_PROFILES="...,speech-gpu,..."

# Services neu starten
sudo docker compose -p localai -f docker-compose.local.yml down faster-whisper openedai-speech
sudo docker compose -p localai -f docker-compose.local.yml pull faster-whisper-gpu openedai-speech-gpu
sudo docker compose -p localai -f docker-compose.local.yml up -d faster-whisper-gpu openedai-speech-gpu
```

### Models in der UI konfigurieren

Nach dem ersten Start: **`http://${SERVER_IP}:8100`**

#### 1ï¸âƒ£ Embedding Model (KRITISCH fÃ¼r PDFs!)

**Settings â†’ Models â†’ "+ Add Model" bei Embeddings:**
```
Provider: ollama
Model Name: nomic-embed-text
Display Name: Ollama Embeddings
```

**Warum wichtig:** Ohne Embedding Model kÃ¶nnen PDFs nicht durchsucht werden!

#### 2ï¸âƒ£ Speech-to-Text Model

**Settings â†’ Models â†’ "+ Add Model" bei Speech-to-Text:**
```
Provider: openai_compatible
Model Name: whisper-1
Display Name: Local Whisper STT
```

#### 3ï¸âƒ£ Text-to-Speech Model

**Settings â†’ Models â†’ "+ Add Model" bei Text-to-Speech:**
```
Provider: openai_compatible
Model Name: tts-1
Display Name: Local TTS
```

#### 4ï¸âƒ£ AI Chat & Transformation Models

**Settings â†’ AI Models â†’ Ollama hinzufÃ¼gen:**
```
Provider: Ollama
Base URL: http://ollama:11434
Models: qwen2.5:7b-instruct-q4_K_M
```

---

## ğŸ“š Use Cases

### ğŸ™ï¸ Deutsche Podcasts erstellen

#### Schritt 1: Speaker Profile mit gÃ¼ltigen Voices

**Podcasts â†’ Speaker Profiles â†’ "+ New Profile"**

```
Name: Deutscher Speaker
Description: Deutschsprachiger Podcast-Speaker

Speaker Configuration:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Speaker 1 (Host):                   â”‚
â”‚ - Name: Moderator                   â”‚
â”‚ - Voice: alloy âœ…                   â”‚
â”‚ - Role: Deutscher Podcast-Moderator â”‚
â”‚ - Personality: Professionell, freundlich â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**VerfÃ¼gbare Voices (alle sprechen Deutsch!):**
- `alloy` - Neutral, ausgewogen
- `echo` - MÃ¤nnlich, warm
- `fable` - MÃ¤nnlich, krÃ¤ftig
- `onyx` - MÃ¤nnlich, tief âœ¨ **Empfohlen fÃ¼r deutsche Podcasts**
- `nova` - Weiblich, freundlich
- `shimmer` - Weiblich, weich

**âš ï¸ WICHTIG:** Voice muss ein gÃ¼ltiger Name sein (z.B. `alloy`), **NICHT** eine Nummer wie `1`!

#### Schritt 2: Episode Profile fÃ¼r deutsche Podcasts

**Podcasts â†’ Episode Profiles â†’ "+ New Profile"**

```
Name: Deutscher Podcast
Number of Speakers: 2

Default Briefing:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Erstelle einen professionellen deutschen Podcast Ã¼ber die gegebenen Quellen.

WICHTIG: Die GESAMTE Konversation muss auf Deutsch sein!

Der Podcast soll:
- Informativ aber zugÃ¤nglich sein
- Die Hauptpunkte der Quellen behandeln
- NatÃ¼rliche GesprÃ¤chsdynamik haben
- Fachbegriffe erklÃ¤ren

Host-Rolle:
- Stellt kluge Fragen
- Leitet die Diskussion
- Fasst Kernpunkte zusammen

Expert-Rolle:
- Gibt fundierte Antworten
- ErklÃ¤rt Details
- Bringt praktische Beispiele
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Outline Model: qwen2.5:7b-instruct-q4_K_M (ollama)
Transcript Model: qwen2.5:7b-instruct-q4_K_M (ollama)
Speaker Profile: Deutscher Speaker (von oben)
```

#### Schritt 3: Podcast generieren

1. **Ã–ffne ein Notebook** mit deutschen Quellen (PDF, YouTube, etc.)
2. **Klicke "Generate Podcast"**
3. **WÃ¤hle Quellen** aus
4. **WÃ¤hle "Deutscher Podcast" Profile**
5. **Generate**

**Ergebnis:** 
- âœ… Transcript komplett auf Deutsch
- âœ… Audio mit deutschen Stimmen
- âœ… NatÃ¼rliche deutsche Konversation

#### Troubleshooting: Podcast bleibt auf Englisch

**Problem:** LLM generiert trotz Briefing englischen Text

**LÃ¶sung:** VerstÃ¤rke die deutsche Anweisung im Briefing:

```
KRITISCH: Dieser Podcast MUSS zu 100% auf Deutsch sein!
Jeder Satz, jede Einleitung, jede Frage und Antwort auf DEUTSCH!
Kein einziges englisches Wort verwenden!

Beispiel-Dialog auf Deutsch:
Host: "Willkommen zum heutigen Podcast..."
Expert: "Vielen Dank fÃ¼r die Einladung..."
```

---

### ğŸ“º YouTube Videos transkribieren

#### Use Case: YouTube Video â†’ Durchsuchbare Transkription

**Schritt 1: Video als Quelle hinzufÃ¼gen**

```
1. Neues Notebook erstellen: "YouTube Research"
2. Add Source â†’ URL
3. YouTube-Link eingeben: https://www.youtube.com/watch?v=VIDEO_ID
4. Submit
```

**Was passiert automatisch:**
- âœ… Video wird analysiert
- âœ… Audio wird extrahiert
- âœ… Whisper (lokal!) transkribiert das Audio
- âœ… Text wird in Embeddings konvertiert
- âœ… Video ist durchsuchbar

**Performance:**
- CPU: ~3 Minuten fÃ¼r 10-Minuten-Video
- GPU: ~45 Sekunden fÃ¼r 10-Minuten-Video

#### Use Case: YouTube â†’ Zusammenfassung

**Schritt 2: Mit Video-Content chatten**

```
Chat-Prompt:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Erstelle eine strukturierte Zusammenfassung dieses YouTube-Videos auf Deutsch:

1. Hauptthemen (3-5 Punkte)
2. Wichtigste Erkenntnisse
3. Praktische Takeaways
4. Zitate mit Zeitstempeln

Format: Markdown mit Ãœberschriften
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Ergebnis:** Strukturierte Zusammenfassung mit Quellenangaben und Zeitstempeln!

#### Use Case: YouTube â†’ Deutscher Podcast

**Schritt 3: Podcast aus YouTube-Video generieren**

```
1. YouTube-Video ist als Quelle im Notebook
2. Generate Podcast
3. Profile: "Deutscher Podcast" wÃ¤hlen
4. Generate

Ergebnis: Professioneller deutscher Podcast Ã¼ber das YouTube-Video!
```

**Praktisches Beispiel:**
- Englisches Tech-Video auf YouTube
- Deutsches Transkript und Podcast erstellen
- Perfekt fÃ¼r Content-Lokalisierung!

---

### ğŸ“„ PDF Research & Analyse

#### Use Case: Einzelnes PDF analysieren

**Schritt 1: PDF hochladen**

```
1. Notebook erstellen: "Dokument-Analyse"
2. Add Source â†’ Upload File
3. PDF auswÃ¤hlen
4. Upload

Automatisch:
- âœ… Text wird extrahiert
- âœ… Mit Ollama Embeddings verarbeitet
- âœ… Durchsuchbar und chatbar
```

#### Use Case: Mit PDF chatten

**Praktische Chat-Prompts:**

```
ğŸ“‹ Zusammenfassung:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Fasse dieses Dokument in 5 Kernpunkten zusammen.
Nutze Stichpunkte und sei prÃ¤zise.

â“ Spezifische Fragen:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Was sagt das Dokument Ã¼ber [Thema]?
Zitiere relevante Stellen mit Seitenangabe.

ğŸ” Analyse:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Analysiere die Argumentation in diesem Dokument.
Identifiziere StÃ¤rken und SchwÃ¤chen.

ğŸ“Š Vergleich (mit mehreren PDFs):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Vergleiche die AnsÃ¤tze in Dokument A und B bezÃ¼glich [Thema].
```

#### Use Case: Insights generieren

**Features â†’ Create Insight:**

```
Insight-Types:
- Summary: Zusammenfassung des gesamten Dokuments
- Key Points: Hauptpunkte als Liste
- Questions: Generiere Fragen zum Dokument
- Action Items: Handlungsempfehlungen
```

#### Use Case: Multi-PDF Research

**Workflow:**

```
1. Notebook: "Literatur-Review"
2. Mehrere PDFs hochladen (Paper, Artikel, etc.)
3. Cross-Reference Prompts:

   "Welche Gemeinsamkeiten haben die Papers bezÃ¼glich [Methode]?"
   "Finde WidersprÃ¼che zwischen den Quellen."
   "Erstelle eine vergleichende Tabelle der AnsÃ¤tze."
```

**Open Notebook zitiert automatisch die richtigen PDFs!**

---

### ğŸ”„ Advanced Workflows

#### Workflow 1: YouTube â†’ Blog Post

```
1. YouTube-Video als Quelle hinzufÃ¼gen
2. Automatische Transkription
3. Transformation erstellen:

Prompt:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Erstelle einen deutschen Blog-Post basierend auf diesem Video:

- Catchy Titel und Einleitung
- 3-4 Hauptabschnitte mit Ãœberschriften
- Praktische Beispiele aus dem Video
- Call-to-Action am Ende
- Markdown-Format

Zielgruppe: Deutschsprachige Tech-Community
Ton: Professionell aber zugÃ¤nglich
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

4. Ergebnis: Fertiger Blog-Post auf Deutsch!
```

#### Workflow 2: Research â†’ Podcast

```
1. Notebook mit Multiple Sources:
   - 3 PDFs Ã¼ber AI
   - 2 YouTube Videos
   - 5 Artikel

2. Generate Podcast:
   - Episode Profile: Deutscher Podcast
   - Speakers: 3 (Moderator + 2 Experten)
   
3. Ollama erstellt:
   - Outline Ã¼ber alle Quellen
   - Synthesis der Informationen
   - NatÃ¼rlicher deutscher Dialog
   
4. TTS generiert:
   - Audio fÃ¼r alle 3 Speaker
   - GPU-beschleunigt in Minuten
   - Professional klingendes Ergebnis
```

#### Workflow 3: n8n Automatisierung

**n8n Workflow fÃ¼r automatisches YouTube-Processing:**

```
1. [Webhook] - YouTube-URL empfangen
2. [HTTP Request] â†’ Open Notebook API
   POST /api/sources
   Body: { "url": "{{$json.youtube_url}}", "notebook_id": "..." }
   
3. [Wait] 2 Minuten (fÃ¼r Transkription)

4. [HTTP Request] â†’ Generate Summary
   POST /api/notebooks/{{notebook_id}}/chat
   Body: { "message": "Erstelle deutsche Zusammenfassung" }
   
5. [HTTP Request] â†’ Generate Podcast
   POST /api/notebooks/{{notebook_id}}/podcast
   Body: { "episode_profile": "Deutscher Podcast" }
   
6. [Slack/Email] â†’ Benachrichtigung mit Links

Ergebnis: Vollautomatische YouTube â†’ Podcast Pipeline!
```

**API-Beispiele:** Siehe `http://${SERVER_IP}:8101/docs`

---

## ğŸ’¡ Best Practices

### 1. Podcast-Produktion

**âœ… DO:**
- Nutze GPU-Version fÃ¼r schnellere Generierung (4-5x)
- Spezifiziere Sprache explizit im Briefing ("auf Deutsch!")
- Verwende verschiedene Voices fÃ¼r verschiedene Speaker
- Teste mit kurzen Quellen zuerst
- Setze klare Rollen fÃ¼r jeden Speaker

**âŒ DON'T:**
- Voice-ID als Nummer (z.B. `1`) - nutze Namen (`alloy`)
- Zu lange Quellen ohne Chunking (max. 10.000 WÃ¶rter)
- GPT-5 extended thinking Modelle fÃ¼r Podcasts (verursacht Fehler)
- Mehrsprachige Prompts (entweder Deutsch ODER Englisch)

### 2. YouTube-Verarbeitung

**Optimale Einstellungen:**

```yaml
Whisper Model: Systran/faster-distil-whisper-large-v3
Compute: GPU (wenn verfÃ¼gbar)
Chunk Size: 30 Sekunden
Language: auto-detect

Performance-Tipp:
- Videos > 30 Min: In mehrere Notebooks aufteilen
- Livestreams: In 10-Min-Segmente teilen
```

### 3. PDF-Analyse

**Embedding-Strategie:**

```
Kleine PDFs (<50 Seiten):
  Embedding Model: nomic-embed-text (Ollama)
  Chunk Size: 1000 Tokens
  
GroÃŸe PDFs (>100 Seiten):
  Embedding Model: nomic-embed-text
  Chunk Size: 500 Tokens
  Split-Strategie: Nach Ãœberschriften
  
Performance:
  CPU: ~30 Sekunden pro 10 Seiten
  Mit Ollama: Unbegrenzte Embeddings kostenlos!
```

### 4. Prompt-Engineering fÃ¼r deutsche Ausgabe

**Effektive Prompts:**

```
âŒ Schlecht:
"Erstelle einen Podcast"
(â†’ wird wahrscheinlich englisch)

âœ… Gut:
"Erstelle einen professionellen deutschen Podcast.
ALLE Dialoge mÃ¼ssen auf Deutsch sein.
Beispiel: 'Willkommen zum Podcast Ã¼ber...'"
(â†’ LLM versteht die Erwartung klar)

âœ… Optimal:
"Du bist ein deutscher Podcast-Producer.
Erstelle einen informativen Podcast auf Deutsch Ã¼ber [Thema].
Der Host ist deutscher Muttersprachler und spricht nur Deutsch.
Der Experte antwortet ausschlieÃŸlich auf Deutsch.

Beginne mit: 'Herzlich willkommen...'"
(â†’ Maximale Klarheit + Beispiel)
```

### 5. Resource Management

**GPU Memory Monitoring:**

```bash
# GPU-Auslastung Ã¼berwachen
watch -n 2 nvidia-smi

# Bei mehreren GPUs: Spezifische GPU wÃ¤hlen
# (bereits in docker-compose.local.yml konfiguriert)

# Memory-Nutzung:
- faster-whisper: ~256MB VRAM
- openedai-speech: ~512MB VRAM (beim Generieren)
- Gesamt: ~1GB VRAM ausreichend
```

---

## ğŸ¬ Praktische Szenarien

### Szenario 1: WÃ¶chentlicher News-Podcast

**Setup:**

```
1. Episode Profile: "Tech News DE"
   Briefing: "Erstelle einen dynamischen deutschen Tech-News Podcast.
             Host fasst Nachrichten zusammen, Experte analysiert Auswirkungen."
   Speakers: 2 (alloy + onyx)
   
2. WÃ¶chentlicher Workflow:
   - Montag: 5 Tech-Artikel als Quellen hinzufÃ¼gen
   - Podcast generieren (GPU: ~2 Minuten)
   - Audio herunterladen
   - Auf Plattformen verÃ¶ffentlichen
   
3. Automatisierung (optional):
   - n8n Workflow: RSS â†’ Open Notebook â†’ Podcast
   - Automatischer Upload zu Podcast-Plattform
```

### Szenario 2: Uni-Vorlesung transkribieren

**Setup:**

```
1. Vorlesungs-Video (YouTube oder Upload)
2. Automatische Transkription mit Whisper GPU
3. Ergebnis:
   - Durchsuchbares Transkript
   - Timestamps fÃ¼r Navigation
   - Chat mit Vorlesungsinhalten
   
4. Lern-Funktionen:
   - "ErklÃ¤re Konzept X aus der Vorlesung"
   - "Erstelle Zusammenfassung fÃ¼r PrÃ¼fung"
   - "Generiere Flashcards"
```

### Szenario 3: Unternehmens-Documentation

**Setup:**

```
1. Notebook: "Firmen-Dokumentation"
2. Quellen:
   - PDFs: Richtlinien, Prozesse, VertrÃ¤ge
   - Videos: Onboarding, Trainings
   - Artikel: Best Practices
   
3. Use Cases:
   - Mitarbeiter-Onboarding: "Was muss ich Ã¼ber [Prozess] wissen?"
   - Compliance: "Finde alle Regeln zu [Thema]"
   - Podcast: "Erstelle deutsche EinfÃ¼hrung fÃ¼r neue Mitarbeiter"
```

### Szenario 4: Content Repurposing

**Workflow:**

```
Ausgangspunkt: 1 langes YouTube-Video (45 Min, Englisch)

â†“ Open Notebook Processing

Ergebnisse:
  â”œâ”€ Deutsches Transkript (Whisper)
  â”œâ”€ Deutsche Zusammenfassung (Ollama)
  â”œâ”€ Deutscher Podcast (10 Min, TTS)
  â”œâ”€ Blog-Post auf Deutsch (Transformation)
  â”œâ”€ Social Media Posts (Kurz-Zusammenfassungen)
  â””â”€ FAQ (Generiert aus Inhalt)

Time: ~10 Minuten (mit GPU)
Cost: 0â‚¬ (alles lokal!)
```

---

## ğŸ”§ Troubleshooting

### Problem: "Missing required models: Embedding Model"

**Ursache:** Kein Embedding Model konfiguriert

**LÃ¶sung:**
```
Settings â†’ Models â†’ Embedding Model:
- Provider: ollama
- Model Name: nomic-embed-text
```

### Problem: Podcast-Audio Fehler "KeyError: '1'"

**Ursache:** UngÃ¼ltige Voice-ID im Speaker Profile

**LÃ¶sung:**
```
Podcasts â†’ Speaker Profiles â†’ Profile bearbeiten
- Ã„ndere Voice von "1" â†’ "alloy" (oder andere gÃ¼ltige Voice)
- GÃ¼ltig: alloy, echo, fable, onyx, nova, shimmer
- UngÃ¼ltig: Zahlen oder custom Namen
```

### Problem: Podcast bleibt Englisch trotz deutschem Briefing

**Ursache:** LLM ignoriert Sprachanweisung

**LÃ¶sung:**
```
1. VerstÃ¤rke Anweisung im Briefing:
   "KRITISCH: 100% DEUTSCH! Kein Englisch!"
   
2. Gib Beispiel-Dialoge auf Deutsch:
   "Host: 'Herzlich willkommen zum Podcast...'"
   
3. Falls weiterhin Probleme:
   - Nutze stÃ¤rkeres Modell (z.B. GPT-4o via API)
   - Oder erstelle Outline manuell auf Deutsch
```

### Problem: YouTube-Transkription schlÃ¤gt fehl

**Ursache:** Video nicht verfÃ¼gbar, Copyright, oder zu lang

**LÃ¶sung:**
```
1. PrÃ¼fe Video-URL im Browser
2. Bei Copyright-Videos: Download und Upload als File
3. Lange Videos (>2h): In Teile splitten:
   
   # YouTube-Video herunterladen
   yt-dlp -f "best[height<=720]" VIDEO_URL
   
   # In 30-Min Segmente teilen
   ffmpeg -i video.mp4 -c copy -map 0 -segment_time 1800 -f segment segment_%03d.mp4
   
   # Einzeln in Open Notebook hochladen
```

### Problem: Slow Performance trotz GPU

**Diagnose:**

```bash
# PrÃ¼fe ob GPU wirklich genutzt wird
docker logs faster-whisper 2>&1 | grep -i "device"
# Sollte zeigen: "device=cuda" NICHT "device=cpu"

docker logs openedai-speech 2>&1 | grep -i cuda
# Sollte CUDA-Version zeigen

# GPU-Auslastung wÃ¤hrend Generierung
nvidia-smi
# Sollte >0% GPU-Util zeigen wÃ¤hrend Podcast generiert wird
```

**LÃ¶sungen:**

```
1. Falsch konfiguriert:
   - PrÃ¼fe COMPOSE_PROFILES in .env: muss "speech-gpu" sein
   - Container neu erstellen: sudo docker compose ... up -d --force-recreate

2. GPU Memory voll:
   - Andere GPU-Prozesse beenden
   - Oder auf zweite GPU umstellen

3. Alte Container laufen noch:
   docker ps -a | grep faster-whisper
   # Alle alten Container lÃ¶schen
```

### Problem: DNS Fehler bei PDF-Processing

**Fehler:** `[Errno -3] Temporary failure in name resolution`

**Ursache:** Ollama nicht erreichbar oder kein Embedding Model

**LÃ¶sung:**

```bash
# 1. PrÃ¼fe Ollama Verbindung
docker exec open-notebook curl -s http://ollama:11434/api/tags

# 2. PrÃ¼fe ob Embedding Model in UI konfiguriert ist
# Settings â†’ Models â†’ Embedding Model muss gesetzt sein!

# 3. PrÃ¼fe Docker Netzwerk
docker network inspect localai_network | grep -E "open-notebook|ollama"
# Beide mÃ¼ssen im selben Netzwerk sein

# 4. Container im richtigen Projekt starten
sudo docker compose -p localai -f docker-compose.local.yml restart open-notebook
```

---

## ğŸ“Š Performance-Benchmarks

**Hardware:** 2x NVIDIA RTX 3090, AMD Ryzen, 128GB RAM

| Task | CPU | GPU | Speedup |
|------|-----|-----|---------|
| YouTube 10 Min transkribieren | 180s | 45s | **4.0x** |
| Podcast generieren (27 Segmente) | 90s | 20s | **4.5x** |
| PDF embedden (50 Seiten) | 30s | 30s | 1.0x Â¹ |

Â¹ *Embedding lÃ¤uft auf Ollama (CPU), nicht auf Speech Services*

**Empfehlung:**
- **Speech Services:** GPU fÃ¼r Podcasts & Transkription
- **Ollama:** GPU fÃ¼r Embeddings & Chat (wenn genug VRAM)
- **Kombination:** GrÃ¶ÃŸter Performance-Gewinn!

---

## ğŸ”— API Integration

### REST API Beispiele

**Podcast programmatisch erstellen:**

```python
import requests

# 1. Source hochladen
response = requests.post(
    f"http://{SERVER_IP}:8101/api/sources",
    files={"file": open("dokument.pdf", "rb")},
    data={"notebook_id": "notebook:xxx"}
)
source_id = response.json()["id"]

# 2. Podcast generieren
response = requests.post(
    f"http://{SERVER_IP}:8101/api/podcasts/generate",
    json={
        "notebook_id": "notebook:xxx",
        "source_ids": [source_id],
        "episode_profile": "Deutscher Podcast",
        "name": "Mein Podcast"
    }
)

episode_id = response.json()["episode_id"]

# 3. Audio herunterladen
audio_url = f"http://{SERVER_IP}:8101/api/podcasts/episodes/{episode_id}/audio"
```

**VollstÃ¤ndige API-Dokumentation:** `http://${SERVER_IP}:8101/docs`

---

## ğŸ“ Tipps & Tricks

### Tipp 1: Episode Profile Templates

**Interview-Style (2 Speaker):**
```
Host: alloy (neutral)
Guest: nova (freundlich)
Briefing: "Informatives Interview, Host stellt Fragen"
```

**Panel-Diskussion (3 Speaker):**
```
Moderator: alloy
Expert 1: onyx (autoritativ)
Expert 2: echo (warm)
Briefing: "Lebhafte Diskussion mit verschiedenen Perspektiven"
```

**Solo-PrÃ¤sentation (1 Speaker):**
```
Presenter: fable (krÃ¤ftig)
Briefing: "Klare, strukturierte PrÃ¤sentation der Inhalte"
```

### Tipp 2: Ollama Model-Auswahl

```
FÃ¼r Chat & Zusammenfassungen:
  qwen2.5:7b-instruct-q4_K_M âœ…
  - Schnell
  - Gute deutsche QualitÃ¤t
  - 4GB VRAM
  
FÃ¼r Embeddings:
  nomic-embed-text âœ…
  - Spezialisiert fÃ¼r Embeddings
  - Sehr schnell
  - 1GB VRAM
  
FÃ¼r lange Dokumente:
  qwen2.5:14b (wenn genug VRAM)
  - Bessere QualitÃ¤t
  - LÃ¤ngerer Context
  - 8GB VRAM
```

### Tipp 3: Multi-Source Strategie

**Organizational Pattern:**

```
Projekt-Notebook/
â”œâ”€â”€ Research Papers (10 PDFs)
â”œâ”€â”€ YouTube Tutorials (5 Videos)
â”œâ”€â”€ Expert Interviews (3 Audio Files)
â””â”€â”€ Articles (15 Web Pages)

Workflow:
1. Alle Quellen hinzufÃ¼gen
2. Tags vergeben (z.B. "basics", "advanced", "case-study")
3. Filtern nach Tags fÃ¼r spezifische Podcasts
4. Cross-Reference Analyse mÃ¶glich
```

### Tipp 4: Backup-Strategie

```bash
# Open Notebook Daten sichern
cd ~/ai-launchkit-local

# Wichtige Verzeichnisse:
./open-notebook/data/      # Uploaded files, embeddings
./open-notebook/surreal/   # SurrealDB (alle Notebooks, Settings)

# Backup erstellen
tar -czf open-notebook-backup-$(date +%Y%m%d).tar.gz open-notebook/

# Bei Kopia-Backup automatisch mit erfasst!
```

---

## ğŸŒŸ Advanced Features

### Feature: Custom Transformations

**Eigene Content-Transformationen erstellen:**

```
Settings â†’ Transformations â†’ "+ New Transformation"

Name: Deutsche Executive Summary
Prompt:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Erstelle eine Executive Summary auf Deutsch:

1. Situation (2 SÃ¤tze)
2. Problem (2 SÃ¤tze)
3. LÃ¶sung (3 SÃ¤tze)
4. Empfehlung (2 SÃ¤tze)

Format: Professionell, prÃ¤gnant, Entscheider-Sprache
Max. 150 WÃ¶rter
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Anwendung: Bei jeder Quelle verfÃ¼gbar als Quick Action!
```

### Feature: Speaker Personalities

**Charakterisierte Speaker erstellen:**

```
Speaker: "Deutscher Tech-ErklÃ¤rer"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Role: Deutscher Tech-Journalist            â”‚
â”‚                                            â”‚
â”‚ Personality:                               â”‚
â”‚ - ErklÃ¤rt komplexe Konzepte einfach       â”‚
â”‚ - Nutzt Analogien und Beispiele           â”‚
â”‚ - Enthusiastisch aber nicht Ã¼bertrieben   â”‚
â”‚ - Spricht perfektes Hochdeutsch           â”‚
â”‚                                            â”‚
â”‚ Voice: onyx                                â”‚
â”‚ Style: Professionell, zugÃ¤nglich          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ergebnis: Konsistenter Character Ã¼ber alle Podcasts!
```

---

## ğŸ“ˆ Performance-Optimierung

### GPU-Optimierung

**Optimale docker-compose Konfiguration:**

```yaml
# GPU-Version aktiviert beide Speech Services mit CUDA
openedai-speech-gpu:
  image: ghcr.io/matatonic/openedai-speech:latest
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - NVIDIA_DRIVER_CAPABILITIES=compute,utility

faster-whisper-gpu:
  image: fedirz/faster-whisper-server:latest-cuda
  environment:
    - WHISPER__DEVICE=cuda
    - WHISPER__COMPUTE_TYPE=float16
```

**Verifikation:**

```bash
# CUDA-Nutzung prÃ¼fen
docker logs faster-whisper 2>&1 | grep "CUDA Version"
# Output: CUDA Version 12.2.2 âœ…

# GPU Memory wÃ¤hrend Podcast-Generierung
nvidia-smi
# faster-whisper: ~256MB
# openedai-speech: ~512MB (wÃ¤hrend Generierung)
```

### Ollama-Optimierung

**Model Quantization fÃ¼r bessere Performance:**

```bash
# Auf Ubuntu Server
docker exec ollama ollama list

# Empfohlene Modelle:
qwen2.5:7b-instruct-q4_K_M  # Balanced (4GB VRAM)
qwen2.5:7b-instruct-q8_0    # Higher Quality (7GB VRAM)
qwen2.5:14b-instruct-q4_K_M # Best Quality (8GB VRAM)
```

---

## ğŸŒ WeiterfÃ¼hrende Links

- **[Setup-Dokumentation](OPEN_NOTEBOOK_SETUP.md)** - Installation und Grundkonfiguration
- **[TTS Integration](OPEN_NOTEBOOK_TTS_INTEGRATION.md)** - Speech Services Detailkonfiguration
- **[Open Notebook GitHub](https://github.com/lfnovo/open-notebook)** - Upstream-Projekt
- **[API Dokumentation](http://${SERVER_IP}:8101/docs)** - REST API Reference

---

## ğŸ“ Zusammenfassung

### Was Sie mit Open Notebook + AI LaunchKit erreichen:

âœ… **Komplett lokale AI-Verarbeitung:**
- Keine Cloud-API-Kosten
- Volle Datenkontrolle
- Unbegrenzte Nutzung

âœ… **Deutsche Content-Produktion:**
- YouTube â†’ Deutscher Podcast
- PDF â†’ Deutsche Zusammenfassung
- Multi-Source â†’ Deutscher Blog-Post

âœ… **GPU-Beschleunigung:**
- 4-5x schnellere Verarbeitung
- Professional Audio-QualitÃ¤t
- Minuten statt Stunden

âœ… **Automatisierung:**
- n8n Integration
- REST API fÃ¼r Custom Workflows
- Batch-Processing mÃ¶glich

### NÃ¤chste Schritte:

1. âœ… Models in UI konfigurieren (Ollama, STT, TTS, Embeddings)
2. âœ… Deutscher Podcast-Profile erstellen
3. âœ… Ersten Podcast generieren und testen
4. ğŸš€ Advanced Workflows mit n8n automatisieren

**Viel Erfolg mit Open Notebook!** ğŸ™ï¸

---

*Dokumentation erstellt: Oktober 2025 | AI LaunchKit Version: Latest*
