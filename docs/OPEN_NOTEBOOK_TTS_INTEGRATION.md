# Open Notebook - Lokale TTS Service Integration

## üéØ √úbersicht

Diese Anleitung zeigt dir, wie du die **lokalen TTS-Services** (OpenedAI Speech) des AI LaunchKit mit Open Notebook nutzt, um **kostenlos** Podcasts zu generieren.

## ‚úÖ Voraussetzungen

1. **Speech Services aktiviert:** Das `speech` Profil muss aktiv sein
2. **Services laufen:**
   ```bash
   # Pr√ºfe ob Services laufen:
   curl http://AISERVER:8080/health  # Faster Whisper (STT)
   curl http://AISERVER:8081/health  # OpenedAI Speech (TTS)
   ```
3. **docker-compose.local.yml korrekt konfiguriert** (siehe unten)

## üìã Konfiguration

### Schritt 1: Environment-Variable in docker-compose.local.yml

Die docker-compose.local.yml wurde bereits korrigiert und enth√§lt:

```yaml
open-notebook:
  environment:
    # F√ºr Speech-to-Text (Transkription)
    - WHISPER_API_BASE=http://faster-whisper:8000
    
    # F√ºr Text-to-Speech (Podcast-Generierung)
    - OPENAI_COMPATIBLE_BASE_URL_TTS=http://openedai-speech:8000/v1
```

**‚ö†Ô∏è WICHTIG:** 
- Variable hei√üt `OPENAI_COMPATIBLE_BASE_URL_TTS` (nicht `OPENAI_SPEECH_API_BASE`)
- Pfad endet mit `/v1` (OpenAI API Standard)

### Schritt 2: Container neu starten

**Auf dem Ubuntu Server:**

```bash
cd ~/ai-launchkit-local && sudo docker rm -f open-notebook && sudo docker compose -f docker-compose.local.yml up -d open-notebook && sleep 15 && echo "=== Verifiziere Environment-Variable ===" && docker exec open-notebook env | grep OPENAI_COMPATIBLE_BASE_URL_TTS
```

**Erwartete Ausgabe:**
```
=== Verifiziere Environment-Variable ===
OPENAI_COMPATIBLE_BASE_URL_TTS=http://openedai-speech:8000/v1
```

### Schritt 3: TTS Model in Open Notebook UI hinzuf√ºgen

**WICHTIG:** Du konfigurierst **NICHT den Provider**, sondern f√ºgst ein **Model** hinzu!

1. **√ñffne:** `http://AISERVER:8100`
2. **Gehe zu:** Settings (‚öôÔ∏è) ‚Üí **Models**
3. **Im "Text-to-Speech" Bereich:** Klicke **"+ Add Model"**
4. **Konfiguriere das Model:**
   ```
   Provider: openai_compatible (aus Dropdown w√§hlen)
   Model Name: tts-1
   Display Name: Local OpenedAI TTS
   ```
5. **Speichern**

**‚ö†Ô∏è KEINE Base URL eingeben!** Die Base URL kommt automatisch aus der Environment-Variable `OPENAI_COMPATIBLE_BASE_URL_TTS`.

### Schritt 4: Optional - Als Default setzen

In Settings ‚Üí Models kannst du "Local OpenedAI TTS" als **Standard TTS Model** setzen.

## üéôÔ∏è Podcast mit lokalem TTS generieren

### Episode Profile erstellen

1. **Gehe zu:** Podcasts ‚Üí Episode Profiles ‚Üí **"+ New Profile"**
2. **Konfiguriere:**
   ```
   Name: Mein Lokales Podcast-Profil
   Number of Speakers: 2 (oder 1, 3, 4)
   ```

3. **Speaker konfigurieren:**
   ```
   Speaker 1 (Host):
   - Name: Host
   - TTS Model: Local OpenedAI TTS (das hinzugef√ºgte Model)
   - Voice: alloy
   - Role: "Professional host, asks engaging questions"
   
   Speaker 2 (Expert):
   - Name: Expert
   - TTS Model: Local OpenedAI TTS
   - Voice: nova
   - Role: "Subject matter expert, provides detailed answers"
   ```

### Verf√ºgbare Stimmen

OpenedAI Speech unterst√ºtzt:
- **alloy** - Neutral, ausgewogen
- **echo** - M√§nnlich, warm
- **fable** - M√§nnlich, kr√§ftig
- **onyx** - M√§nnlich, tief
- **nova** - Weiblich, freundlich
- **shimmer** - Weiblich, weich

### Podcast generieren

1. **√ñffne ein Notebook** mit Quellen
2. **Klicke:** "Generate Podcast"
3. **W√§hle:** Quellen aus
4. **W√§hle:** Dein Episode Profile
5. **Generate**

**Die Audio-Generierung erfolgt jetzt komplett lokal und kostenlos!** üéâ

## üîç Verifizierung

### Pr√ºfe ob lokaler TTS genutzt wird

W√§hrend der Podcast generiert wird:

```bash
# Logs von Open Notebook
docker logs -f open-notebook

# Logs von OpenedAI TTS (sollte Aktivit√§t zeigen!)
docker logs -f openedai-speech
```

**Du solltest sehen:**
- Open Notebook macht Requests an `openedai-speech:8000/v1/audio/speech`
- OpenedAI Speech generiert Audio-Segmente
- **Keine externen API-Calls** zu OpenAI TTS (keine Kosten!)

### Test-Befehl

Test die TTS API direkt:

```bash
docker exec open-notebook curl -s http://openedai-speech:8000/v1/models
```

Sollte eine Liste von verf√ºgbaren Modellen zur√ºckgeben.

## üìç Wo finde ich den generierten Podcast?

### In der UI

1. **Gehe zu:** Podcasts Seite (Men√º links)
2. **Dein Podcast** sollte dort aufgelistet sein
3. **Klicke darauf** ‚Üí **Play-Button (‚ñ∂Ô∏è)** erscheint
4. **Oder Download-Button (üì•)** nutzen

### Auf dem Filesystem

```bash
# Auf dem Server:
cd ~/ai-launchkit-local/open-notebook/data

# Suche nach generierten Audio-Dateien:
find . -name "*.mp3" -o -name "*.wav" -o -name "*.opus"

# Wahrscheinlich in:
ls -lah podcasts/episodes/
```

### Via API

```bash
# Liste alle Podcasts auf:
curl http://AISERVER:8101/api/podcasts

# API Dokumentation:
http://AISERVER:8101/docs
```

## üí∞ Kosten-Vergleich

| Komponente | Cloud (OpenAI) | Lokal (AI LaunchKit) |
|------------|----------------|----------------------|
| **Script-Generierung (LLM)** | $0.01-0.03 per 1K tokens | Kostenlos mit Ollama |
| **Audio-Generierung (TTS)** | $15 per 1M Zeichen | **Kostenlos** ‚úÖ |
| **Gesamt f√ºr 10-Min Podcast** | $2-5 | **$0** ‚úÖ |

## üö® Troubleshooting

### "Not configured" in der UI

**Problem:** Provider zeigt "Not configured" an

**L√∂sung:**
1. Stelle sicher, dass die Environment-Variable gesetzt ist:
   ```bash
   docker exec open-notebook env | grep OPENAI_COMPATIBLE_BASE_URL_TTS
   ```
2. Container muss mit der neuen Variable neu gestartet worden sein
3. In UI: Model hinzuf√ºgen (provider: openai_compatible, model: tts-1)

### TTS funktioniert nicht

**Pr√ºfe:**
```bash
# 1. Service l√§uft?
curl http://localhost:8081/health

# 2. Container kann Service erreichen?
docker exec open-notebook curl -s http://openedai-speech:8000/health

# 3. Environment-Variable richtig gesetzt?
docker exec open-notebook env | grep OPENAI_COMPATIBLE_BASE_URL_TTS
```

### Kein Audio in generiertem Podcast

**M√∂gliche Ursachen:**
1. TTS Model nicht ausgew√§hlt im Episode Profile
2. Service nicht erreichbar
3. Voice-Name falsch geschrieben (case-sensitive!)

**Debug:**
```bash
docker logs open-notebook | grep -i tts
docker logs openedai-speech | tail -50
```

## üéì Best Practices

### 1. Multi-Speaker Setup

Nutze verschiedene Stimmen f√ºr nat√ºrlichere Gespr√§che:

```
Host: alloy oder nova (freundlich)
Expert: onyx oder echo (autoritativ)
Narrator: shimmer oder fable (neutral)
```

### 2. Episode Profile Templates

Erstelle verschiedene Profile f√ºr verschiedene Podcast-Typen:

**Interview-Style:**
- 2 Speaker: alloy (Host) + nova (Guest)
- Professional und zug√§nglich

**Panel-Discussion:**
- 3 Speaker: alloy (Moderator) + echo (Expert 1) + nova (Expert 2)
- Verschiedene Perspektiven

**Solo-Pr√§sentation:**
- 1 Speaker: fable oder onyx
- Authoritative Stimme

### 3. Performance-Optimierung

**F√ºr schnellere Generierung:**
- Nutze k√ºrzere Quellen-Texte
- W√§hle `tts-1` statt `tts-1-hd` (schneller, aber leicht niedrigere Qualit√§t)
- Stelle sicher, dass der Server genug CPU hat

## üîó Weiterf√ºhrende Links

- [Open Notebook Local TTS Guide](https://github.com/lfnovo/open-notebook/blob/main/docs/features/local_tts.md)
- [OpenAI-Compatible Setup](https://github.com/lfnovo/open-notebook/blob/main/docs/features/openai-compatible.md)
- [OpenedAI Speech Projekt](https://github.com/matatonic/openedai-speech)

## üìù Zusammenfassung

**Environment-Variable richtig setzen:**
```yaml
OPENAI_COMPATIBLE_BASE_URL_TTS=http://openedai-speech:8000/v1
```

**In UI nur Model hinzuf√ºgen:**
- Provider: openai_compatible
- Model: tts-1
- **KEINE Base URL eingeben!**

**Bei Podcast-Generierung:**
- Model ausw√§hlen
- Stimme w√§hlen (alloy, echo, fable, onyx, nova, shimmer)
- Generieren ‚Üí Komplett kostenlos! üéâ
